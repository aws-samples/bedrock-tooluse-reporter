# config.yaml - Deep Research Modoki Configuration

# Bedrock モデルの設定
#    モデルIDを追加してストアしておきエイリアス名を設定します
models:
  claude-3.5-sonnet: "us.anthropic.claude-3-5-sonnet-20241022-v2:0"
  claude-3.7-sonnet: "us.anthropic.claude-3-7-sonnet-20250219-v1:0"
  nova-pro: "us.amazon.nova-pro-v1:0"
  deepseek.r1": "deepseek.r1-v1:0"
  mistral-large: "mistral.mistral-large-2407-v1:0"
  llama-3.3: "us.meta.llama3-3-70b-instruct-v1:0"

# 使用するモデルの設定
#   上記エイリアスを指定します
#   primary_modelはconversion apiでPPTを受け取れるモデルである必要があります
primary_model: "claude-3.7-sonnet"
secondary_model: "nova-pro"

# 会話の最大ターン数
#   max_turns: 標準モードのLLM同士の議論回数
#   summary_turns: サマリーモードのLLM同士の議論回数
conversation:
  max_turns: 5
  summary_turns: 3

# 調査の最大回数
#   max_pre_searches: 事前調査の最大回数
#   summary_pre_searches: サマリーモードの事前調査の最大回数
#   max_searched: 議論後の調査の調査最大回数
#   summary_searches: サマリーモード時の議論後の調査最大回数
research:
  max_pre_searches: 40
  summary_pre_searches: 3
  max_searches: 40
  summary_searches: 10

# LLM接続設定
#    profilesには複数のプロファイルを設定できます
#    Throttling が厳しいときは複数アカウント払い出して各アカウントに振り分ける事で回答を得ることができます
#    必ず各Profileの該当RegionでBedrockモデルを利用許諾して設定してからご利用ください
#    例）profiles:
#         - "default"
#         - "profile_two"
#         - "profiel_three"
connection:
  timeout: 1200
  max_retries: 8
  base_delay: 20
  max_delay: 300
  profiles:
    - "default"
  